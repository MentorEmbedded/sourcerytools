From pcisar at ibphoenix.cz  Tue Apr  7 17:55:14 2009
From: pcisar at ibphoenix.cz (Pavel Cisar)
Date: Tue, 07 Apr 2009 19:55:14 +0200
Subject: qmtest and setuptools
Message-ID: <49DB9382.4060007@ibphoenix.cz>

Hi,

We have several packages that depend on qmtest (among others) and we'd
like streamline the installation and maintenance process for end users
via setuptools. Unfortunately it's not possible to install qmtest via
easy_install because your extensions to distutils don't play well with
setuptools (namely config.py is generated with wrong path, but there are
probably other issues as well).

Do you have any plans to adapt qmtest's setup.py to use setuptools (and
even register qmtest on PyPI) ?

best regards
Pavel Cisar
The Firebird Project
www.firebirdsql.org



From stefan at codesourcery.com  Tue Apr  7 18:07:49 2009
From: stefan at codesourcery.com (Stefan Seefeld)
Date: Tue, 07 Apr 2009 14:07:49 -0400
Subject: [qmtest] qmtest and setuptools
In-Reply-To: <49DB9382.4060007@ibphoenix.cz>
References: <49DB9382.4060007@ibphoenix.cz>
Message-ID: <49DB9675.6060401@codesourcery.com>

Pavel Cisar wrote:
> Hi,
>
> We have several packages that depend on qmtest (among others) and we'd
> like streamline the installation and maintenance process for end users
> via setuptools. Unfortunately it's not possible to install qmtest via
> easy_install because your extensions to distutils don't play well with
> setuptools (namely config.py is generated with wrong path, but there are
> probably other issues as well).
>
> Do you have any plans to adapt qmtest's setup.py to use setuptools (and
> even register qmtest on PyPI) ?
>   
We don't have plans, but we would certainly consider patches.

Thanks,
       Stefan


-- 
Stefan Seefeld
CodeSourcery
stefan at codesourcery.com
(650) 331-3385 x718



From rowan at sylvester-bradley.org  Sun Apr 12 15:13:52 2009
From: rowan at sylvester-bradley.org (Rowan Sylvester-Bradley)
Date: Sun, 12 Apr 2009 16:13:52 +0100
Subject: Where to put 'import', function defs etc.
Message-ID: <7343345F16F943BCA8141D46B12CD215@SSK.LOCAL>

Hi,

I'm trying to use QMtest for the first time and am having some difficulties 
getting to grips with it. I hope someone can answer the following questions 
for me (or tell me where to find a tutorial explaining all this). I'm trying 
to test a remote device so all my tests send messages via the serial port 
and receive serial responses. I'm trying to use the python.ExecTest test 
class, and write all my tests in Python.

1. Where do I put 'import' statements, function definitions etc. that my 
tests need?
2. If many of my tests need the same imports and functions, is there a 
generic place to put the imports and function defs where they will be 
accessible to all tests, or do I have to put them in every test?
3. It looks as if each test in QMtest must be self contained and atomic, 
i.e. it must not depend on which tests have already been run, or in which 
order. If this is right, I don't understand how to deal with a situation 
that needs a long sequence of messages to the device under test and 
responses. The prerequisite concept doesn't seem to solve the problem, 
because (as I understand it) although it guarantees that some tests will 
have been run before the current test, it does not guarantee in which order, 
or whether other tests will also have been run, all of which will change the 
state of the device under test. If I genuinely have to make every test 
independent of what's gone before, I will have to start each test with a 
reboot, and then add commands to the test one by one - so if my test 
sequence consists of reboot, send command A, receive response A, send 
command B, receive response B, send command C, receive response C I will 
have to have tests 1 (reboot, send A receive A), 2 (reboot, send A, receive 
A, send B, receive B) and 3 (reboot, send A, receive A, send B, receive B, 
send C, receive C). If I have 100 or more steps in my sequence, this could 
be very tedious. If I could force my tests to run in sequence, I could just 
have tests 1 (reboot, send A, receive A), 2 (send B, receive B) and 3 (send 
C, receive C).
4. How do I make the execution of a test dependent on the results of 
previous tests (i.e. how do I access the results of previous tests from 
within the Python code of a new test)?
5. How do I make the sequence of tests dependent on the results of previous 
tests? E.g. if test B passes, do test C and then test D, or if it fails, do 
test E and then test F.
6. If I'm using the "Python Source Code" part of the python.ExecTest, and 
not the Python Expression section, what is the recommended way of indicating 
to QMtest whether the test has passed or failed?
7. Should or must I make every comparison of expected results with actual 
results a separate QMtest test, or can/should I have multiple comparisons 
within a single QMtest test? In the latter case there would obviously be 
multiple ways in which the test could fail, which would need to be reported.
What are "resources"? Does using these help me solve any of my problems?
8. If I want to create a new test class, where do I put the class 
definition?
9. Is there a simple example of how to add a new test class written in 
Python somewhere?

Many thanks for your help - Rowan 




From seefeld at sympatico.ca  Thu Apr 16 14:44:25 2009
From: seefeld at sympatico.ca (Stefan Seefeld)
Date: Thu, 16 Apr 2009 10:44:25 -0400
Subject: [qmtest] Where to put 'import', function defs etc.
In-Reply-To: <7343345F16F943BCA8141D46B12CD215@SSK.LOCAL>
References: <7343345F16F943BCA8141D46B12CD215@SSK.LOCAL>
Message-ID: <49E74449.20107@sympatico.ca>

Rowan Sylvester-Bradley wrote:
> Hi,
>
> I'm trying to use QMtest for the first time and am having some 
> difficulties getting to grips with it. I hope someone can answer the 
> following questions for me (or tell me where to find a tutorial 
> explaining all this). I'm trying to test a remote device so all my 
> tests send messages via the serial port and receive serial responses. 
> I'm trying to use the python.ExecTest test class, and write all my 
> tests in Python.
>
> 1. Where do I put 'import' statements, function definitions etc. that 
> my tests need?

Your own test classes live in ordinary modules, so all the normal rules 
for coding in Python apply. What turns a test class into a 
QMTest-visible extension class is its registration via QMTest/classes.qmc.

> 2. If many of my tests need the same imports and functions, is there a 
> generic place to put the imports and function defs where they will be 
> accessible to all tests, or do I have to put them in every test?
I presume you put your test definitions into Python modules inside the 
QMTest/ directory in your test database root directory.
I believe that directory is being searched for for imports, so you could 
simply add arbitrary python modules (or entire packages) with shared 
code there, too.

>
> 3. It looks as if each test in QMtest must be self contained and 
> atomic, i.e. it must not depend on which tests have already been run, 
> or in which order.

That's right.

> If this is right, I don't understand how to deal with a situation that 
> needs a long sequence of messages to the device under test and 
> responses. The prerequisite concept doesn't seem to solve the problem, 
> because (as I understand it) although it guarantees that some tests 
> will have been run before the current test, it does not guarantee in 
> which order, or whether other tests will also have been run, all of 
> which will change the state of the device under test.
Right. As tests are (by design) self-contained, they must not result in 
any external state-changes affecting other tests.

If you need to prepare the environment the test will run in, you may put 
that into a 'resource' 
(http://www.codesourcery.com/public/qmtest/qmtest-snapshot/share/doc/qmtest/html/tutorial/concepts-resources.html)

Resources can be shared among many tests (and QMTest will make sure 
resources are set up prior to the dependent test being run, on the 
target the test is being run). In particular, this means a resource is 
set up only once. If you have a sequence of preparational steps that 
need to be repeated for each test, you have to execute them from within 
your test.


> If I genuinely have to make every test independent of what's gone 
> before, I will have to start each test with a reboot, and then add 
> commands to the test one by one - so if my test sequence consists of 
> reboot, send command A, receive response A, send command B, receive 
> response B, send command C, receive response C I will have to have 
> tests 1 (reboot, send A receive A), 2 (reboot, send A, receive A, send 
> B, receive B) and 3 (reboot, send A, receive A, send B, receive B, 
> send C, receive C). If I have 100 or more steps in my sequence, this 
> could be very tedious. If I could force my tests to run in sequence, I 
> could just have tests 1 (reboot, send A, receive A), 2 (send B, 
> receive B) and 3 (send C, receive C).

Why don't you put all the different steps into a single test ? Put 
appropriate validation checkpoints in between the steps, so your test 
lot will tell at which point things have broken, in case it fails.

(Compare that to a CompilationTest involving first compiling a source 
file, then running it. The multiple steps are 1) preprocessing, 2) 
compilation, 3) linking, 4) execution. In case of failure the test will 
report in which of those steps an error happened.)


> 4. How do I make the execution of a test dependent on the results of 
> previous tests (i.e. how do I access the results of previous tests 
> from within the Python code of a new test)?

You don't, as per the design that stipulates all tests being 
independent. (To illustrate one of the rationales: imagine running tests 
in parallel, possibly on a build farm: Test B may run in a different 
universe than test A, and both not knowing anything about each other.)

The concept of 'prerequisite tests' is simply meant as an optimization, 
so you can skip a test it is known to fail, because some other 
'prerequisite' test failed, too. See
http://www.codesourcery.com/public/qmtest/qmtest-snapshot/share/doc/qmtest/html/tutorial/concepts.html#concepts-tests

> 5. How do I make the sequence of tests dependent on the results of 
> previous tests? E.g. if test B passes, do test C and then test D, or 
> if it fails, do test E and then test F.

See above.

> 6. If I'm using the "Python Source Code" part of the python.ExecTest, 
> and not the Python Expression section, what is the recommended way of 
> indicating to QMtest whether the test has passed or failed?
As per the python.ExecTest's documentation, in the absence of an 
expression, the test fails if it throws an exception.

> 7. Should or must I make every comparison of expected results with 
> actual results a separate QMtest test, or can/should I have multiple 
> comparisons within a single QMtest test? In the latter case there 
> would obviously be multiple ways in which the test could fail, which 
> would need to be reported.
Right. Existing test classes are probably not flexible enough if you 
want to distinguish multiple such failure codes.
In that case you may want to write your own test classes and then log 
the failure details in the Result object.

> What are "resources"? Does using these help me solve any of my problems?

Possibly. See above.

> 8. If I want to create a new test class, where do I put the class 
> definition?
That's explained in 
http://www.codesourcery.com/public/qmtest/qmtest-snapshot/share/doc/qmtest/html/tutorial/extending.html

>
> 9. Is there a simple example of how to add a new test class written in 
> Python somewhere?

I'm not sure whether we have complete examples. However, the above 
documentation explains all the details. You may want to copy an existing 
module (such as qm/test/classes/python.py) into your QMTest/ directory, 
register the classes via QMTest/classes.qmc, and then experiment with 
modifications you apply to that code.

Good luck !

       Stefan

-- 

      ...ich hab' noch einen Koffer in Berlin...



From aj.guillon at gmail.com  Mon Apr 20 04:20:43 2009
From: aj.guillon at gmail.com (Adrien Guillon)
Date: Mon, 20 Apr 2009 00:20:43 -0400
Subject: Cluster Testing
Message-ID: <9870a2060904192120s3e636f0fsa8a7e11b486a9e68@mail.gmail.com>

Hello,

I have recently started to use qmtest for testing my open source
project.  My project is designed to run on compute clusters, therefore
I'm looking at how to use qmtest to test my code on a cluster.  My
test cases will do nasty things, like terminate the process on one
node, to see how reliable my application is.  I am hoping that someone
has already tackled this problem, and can provide some code.
Alternatively, I would love to have some help to create an extension
that meets my needs, and contribute that back to the community.

I did see that qmtest has the ability to run commands or compile
applications on remote nodes via SSH or RSH.  I'm not sure what a
cluster test harness would look like, but I imagine that I would want
to transfer source code to a remote host, compile it, and run the
application.  The selection of nodes may play a role in the test as
well, and you might not always want to run the same program on each
node.  For example, I might select a node which is big-endian and a
little-endian node to check that communication between the two is
sane.  I might also test just the server and client communication part
of an application, so I might have two different applications rather
than just one to run.  I may also have multiple clusters to test with,
each with machines with different properties.

I would appreciate general advice on how to proceed with qmtest
development.  Should I develop a test framework independently, then
integrate it later with qmtest?

Thanks,

AJ



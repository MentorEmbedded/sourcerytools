From vsingh at velankani.com  Thu Aug  3 09:32:58 2006
From: vsingh at velankani.com (Vinod Kumar Singh)
Date: Thu, 3 Aug 2006 15:02:58 +0530
Subject: Resource Problem
In-Reply-To: <44BFCB94.9060400@codesourcery.com>
Message-ID: <002301c6b6df$ce81c090$0d15000a@blr.velankani.com>

Hi,

I have created one resource class using QMTest resource and configuring some
parameters. Now I create this my resource class with valid parameters and
want to use in my test script.

I am attaching test.qmt file and resource1 file.

When I run my test script the error comes:-

ERROR   	 The context variable "resource1" was not defined.

Any pointer in this regard is highly appreciated.

Regards,
Vinod
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: vtaftestcase.qmt
Type: application/octet-stream
Size: 595 bytes
Desc: not available
URL: <http://sourcerytools.com/pipermail/qmtest/attachments/20060803/20b4a6e5/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: resource1.qma
Type: application/octet-stream
Size: 432 bytes
Desc: not available
URL: <http://sourcerytools.com/pipermail/qmtest/attachments/20060803/20b4a6e5/attachment-0001.obj>

From dimock at csail.mit.edu  Thu Aug 17 15:45:37 2006
From: dimock at csail.mit.edu (Allyn Dimock)
Date: Thu, 17 Aug 2006 11:45:37 -0400 (EDT)
Subject: algorithms with less storage for producing results.xml?
Message-ID: <Pine.LNX.4.61.0608171101180.7802@cag.csail.mit.edu>


I am running into a problem that as more test are added to out regression 
testing system, and as more informational messages are added the size of
the results.qmr file grows it becomes difficult or impossible to produce
a results.xml file because of memory thrashing or hard limits.

Is there an algorithm for reporting that does not require the entire 
results.xml file to be built in memory?

My understanding of the results.xml format is that it is
<report>
   <suite>
   ( <test id="..." /> )*
   </suite>
   <results>
   ( <annotation key="...">
       text
     </annotation> )*
   ( <result id="..." kind="..." outcome="...">
     ( <annotation name="...">
         text
       </annotation> )*
     </result> )*
   </results>
</report>

It looks as if this format could be generated in two passes over
the results.qmt file(s) without requiring much more memory than
the size of an annotation.  One pass to generate the <test /> entries
and a second pass to generate the <result>...</result> entries.
I don't know Python xml generation packages.  How easy / difficult would 
this be to do?

One might say "this is only putting the problem off to the programs 
parsing the results.xml file" but the event-driven xml parsers do not need 
the whole file to extract data.

[ This had not been an issue for us when using qmtest 2.0: the xml report
not being availble at the time, we reverse engineered the results.qmt
format to generate the reports that we wanted in one pass per report (one 
summary report that was e-mailed to developers and detais were in a 
collection of html files referencable from the rt ticket tracker system).
   In 2.3 we started relying on results.xml since the results.qmt format 
had changed from 2.0 and we did not want to reverse engineer multiple 
times when a non-proprietary format was available. ]

I don't have time to hack on this until after a Sep. 1 release of our 
product.  I can try something then for handling large results.qmr files, 
or one of the gurus could try something earlier if so inclined.

Is this high on other qmtest users lists?

-- Allyn

"Allyn Dimock" <dimock at csail.mit.edu>


From mark at codesourcery.com  Thu Aug 17 20:43:40 2006
From: mark at codesourcery.com (Mark Mitchell)
Date: Thu, 17 Aug 2006 13:43:40 -0700
Subject: [qmtest] algorithms with less storage for producing results.xml?
In-Reply-To: <Pine.LNX.4.61.0608171101180.7802@cag.csail.mit.edu>
References: <Pine.LNX.4.61.0608171101180.7802@cag.csail.mit.edu>
Message-ID: <44E4D4FC.40406@codesourcery.com>

Allyn Dimock wrote:

> It looks as if this format could be generated in two passes over
> the results.qmt file(s) without requiring much more memory than
> the size of an annotation. 

Yes, I believe that's correct.

> I don't know Python xml generation packages.  How easy / difficult would
> this be to do?

It would not be that hard.  IIRC, it may not be possible to generate
"half" of a complete XML entry, so you might have to manually emit the
top-level "<foo>" and "</foo>" markers.  But, the Python libraries would
certainly be happy to generate a result-at-a-time, say.

I think it would be great if you tackled this issue, and I'm sure Stefan
and I would be able to give some pointers.

Thanks,

-- 
Mark Mitchell
CodeSourcery
mark at codesourcery.com
(650) 331-3385 x713


From mark at codesourcery.com  Fri Aug 18 00:34:05 2006
From: mark at codesourcery.com (Mark Mitchell)
Date: Thu, 17 Aug 2006 17:34:05 -0700
Subject: PATCH: Make "qmtest summarize" show resource results, too
Message-ID: <200608180034.k7I0Y52r028365@elphaba.codesourcery.com>


The "qmtest summarize" command can be used to show the results of a
previous run.  You can say "qmtest summarize results.qmr test" to show
just the results from "test".  However, before this patch, there was
no way to show the results of a resource, unless the resource failed,
and, even then, you had to request the results of a test that depended
on the resource.

This patch makes QMTest interpret the IDs given to "qmtest summarize"
as either tests or resources, as convenient.

Applied.

--
Mark Mitchell
CodeSourcery
mark at codesourcery.com
(650) 331-3385 x713

2006-08-17  Mark Mitchell  <mark at codesourcery.com>

	* qm/test/cmdline.py (QMTest.__ExecuteSummarize): Display resource
	results too.

Index: qm/test/cmdline.py
===================================================================
RCS file: /home/qm/Repository/qm/qm/test/cmdline.py,v
retrieving revision 1.119
diff -c -5 -p -r1.119 cmdline.py
*** qm/test/cmdline.py	17 Jul 2006 18:46:06 -0000	1.119
--- qm/test/cmdline.py	18 Aug 2006 00:23:20 -0000
*************** Valid formats are %s.
*** 1451,1478 ****
          # The remaining arguments, if any, are test and suite IDs.
          id_arguments = self.__arguments[1:]
          # Are there any?
          # '.' is an alias for <all>, and thus shadows other selectors.
          if len(id_arguments) > 0 and not '.' in id_arguments:
!             filter = 1
!             # Expand arguments into test IDs.
!             try:
!                 if database:
!                     test_ids = database.ExpandIds(id_arguments)[0]
!                 else:
!                     test_ids = id_arguments
!             except (qm.test.database.NoSuchTestError,
!                     qm.test.database.NoSuchSuiteError), exception:
!                 raise qm.cmdline.CommandError, \
!                       qm.error("no such ID", id=str(exception))
!             except ValueError, exception:
!                 raise qm.cmdline.CommandError, \
!                       qm.error("no such ID", id=str(exception))
          else:
              # No IDs specified.  Show all test and resource results.
              # Don't show any results by test suite though.
!             filter = 0
  
          # Get an iterator over the results.
          try:
              results = base.load_results(results_path, database)
          except Exception, exception:
--- 1451,1478 ----
          # The remaining arguments, if any, are test and suite IDs.
          id_arguments = self.__arguments[1:]
          # Are there any?
          # '.' is an alias for <all>, and thus shadows other selectors.
          if len(id_arguments) > 0 and not '.' in id_arguments:
!             ids = set()
!             # Expand arguments into test/resource IDs.
!             if database:
!                 for id in id_arguments:
!                     extension = database.GetExtension(id)
!                     if not extension:
!                         raise qm.cmdline.CommandError, \
!                               qm.error("no such ID", id = id)
!                     if extension.kind == database.SUITE:
!                         ids.update(extension.GetAllTestAndSuiteIds()[0])
!                     else:
!                         ids.add(id)
!             else:
!                 ids = set(id_arguments)
          else:
              # No IDs specified.  Show all test and resource results.
              # Don't show any results by test suite though.
!             ids = None
  
          # Get an iterator over the results.
          try:
              results = base.load_results(results_path, database)
          except Exception, exception:
*************** Valid formats are %s.
*** 1494,1518 ****
          # Get the expected outcomes.
          outcomes = self.__GetExpectedOutcomes()
  
          resource_results = {}
          for r in results:
-             if filter and r.GetKind() == Result.RESOURCE_SETUP:
-                 resource_results[r.GetId()] = r
              if r.GetKind() != Result.TEST:
!                 if not filter:
                      for s in streams:
                          s.WriteResult(r)
                  continue
              # We now known that r is test result.  If it's not one
              # that interests us, we're done.
!             if filter and r.GetId() not in test_ids:
                  continue
              # If we're filtering, and this test was not run because it
              # depended on a resource that was not set up, emit the
              # resource result here.
!             if (filter
                  and r.GetOutcome() == Result.UNTESTED
                  and r.has_key(Result.RESOURCE)):
                  rid = r[Result.RESOURCE]
                  rres = resource_results.get(rid)
                  if rres:
--- 1494,1518 ----
          # Get the expected outcomes.
          outcomes = self.__GetExpectedOutcomes()
  
          resource_results = {}
          for r in results:
              if r.GetKind() != Result.TEST:
!                 if ids is None or r.GetId() in ids:
                      for s in streams:
                          s.WriteResult(r)
+                 elif r.GetKind() == Result.RESOURCE_SETUP:
+                     resource_results[r.GetId()] = r
                  continue
              # We now known that r is test result.  If it's not one
              # that interests us, we're done.
!             if ids is not None and r.GetId() not in ids:
                  continue
              # If we're filtering, and this test was not run because it
              # depended on a resource that was not set up, emit the
              # resource result here.
!             if (ids is not None
                  and r.GetOutcome() == Result.UNTESTED
                  and r.has_key(Result.RESOURCE)):
                  rid = r[Result.RESOURCE]
                  rres = resource_results.get(rid)
                  if rres:


From mark at codesourcery.com  Fri Aug 18 00:42:15 2006
From: mark at codesourcery.com (Mark Mitchell)
Date: Thu, 17 Aug 2006 17:42:15 -0700
Subject: PATCH: Tweak Host.Run interface 
Message-ID: <200608180042.k7I0gF6o028496@elphaba.codesourcery.com>


The Host extension classes allows you to run programs on remote
machines via the Run method.  The "path" argument is interpreted
differently depending on its form: absolute paths are absolute (of
course), relative paths with at least one directory seperator are
relative to the default directory, and relative paths without a
directory separator search the PATH.  (That was the pre-patch
situation.)

However, that gives no easy way to run a program in the default
directory.  You have to explicitly say "./foo", which is cumbersome
and means the caller has to form OS-specific pathnames (e.g., change
"/" for "\" if running from UNIX to Windows).  So, this patch adds an
explicit "relative" parameter to Run; now if you set Relative to true,
the path is always considered to be relative to the default directory,
and it's the Host extensions responsibility to form a path which makes
sense on the remote machine.

Applied.

--
Mark Mitchell
CodeSourcery
mark at codesourcery.com
(650) 331-3385 x713

2006-08-17  Mark Mitchell  <mark at codesourcery.com>

	* qm/host.py (Host.Run): Add 'relative' parameter.
	(Host.UploadAndRun): Use it.
	* qm/test/classes/ssh_host.py (SSHHost.Run): Add 'relative'
	parameter.

Index: qm/host.py
===================================================================
RCS file: /home/qm/Repository/qm/qm/host.py,v
retrieving revision 1.3
diff -c -5 -p -r1.3 host.py
*** qm/host.py	15 Jun 2006 13:40:14 -0000	1.3
--- qm/host.py	18 Aug 2006 00:35:18 -0000
*************** import os.path
*** 25,35 ****
  
  class Host(Extension):
      """A 'Host' is a logical machine.
  
      Each logical machine has a default directory.  When a file is
!     uploaded to or downloaded from the machine, and a relative patch
      is specified, the patch is relative to the default directory.
      Similarly, when a program is run on the remote machine, its
      initial working directory is the default directory.
  
      The interface presented by 'Host' is a lowest common
--- 25,35 ----
  
  class Host(Extension):
      """A 'Host' is a logical machine.
  
      Each logical machine has a default directory.  When a file is
!     uploaded to or downloaded from the machine, and a relative path
      is specified, the patch is relative to the default directory.
      Similarly, when a program is run on the remote machine, its
      initial working directory is the default directory.
  
      The interface presented by 'Host' is a lowest common
*************** class Host(Extension):
*** 57,74 ****
  
              return None
  
  
  
!     def Run(self, path, arguments, environment = None, timeout = -1):
          """Run a program on the remote host.
  
          'path' -- The name of the program to run, on the remote host.
!         If 'path' is an absolute path or contains no directory
!         separators it is used unmodified; otherwise (i.e., if it is a
!         relative path containing at least one separator) it is
!         interpreted relative to the default directory.
          
          'arguments' -- The sequence of arguments that should be passed
          to the program.
  
          'environment' -- If not 'None', a dictionary of pairs of
--- 57,75 ----
  
              return None
  
  
  
!     def Run(self, path, arguments, environment = None, timeout = -1,
!             relative = False):
          """Run a program on the remote host.
  
          'path' -- The name of the program to run, on the remote host.
!         If 'relative' is true, or if 'path' is not an absolute path
!         but does contain at least one directory separator, then 'path'
!         is interpreted relative to the default directory.  Otherwise,
!         'path' is used unmodified.
          
          'arguments' -- The sequence of arguments that should be passed
          to the program.
  
          'environment' -- If not 'None', a dictionary of pairs of
*************** class Host(Extension):
*** 92,101 ****
--- 93,104 ----
          if environment is not None:
              new_environment = os.environ.copy()
              new_environment.update(environment)
              environment = new_environment
          executable = self.Executable(timeout)
+         if relative:
+             path = os.path.join(os.curdir, path)
          status = executable.Run([path] + arguments, environment)
          return (status, executable.stdout)
  
  
      def UploadFile(self, local_file, remote_file = None):
*************** class Host(Extension):
*** 149,168 ****
  
          The program is uploaded to the default directory on the remote
          host, run, and then deleted."""
          
          self.UploadFile(path)
!         result = self.Run(os.path.join(os.path.curdir,
!                                        os.path.basename(path)),
                            arguments,
                            environment,
!                           timeout)
          self.DeleteFile(path)
          return result
          
          
-         
      def DeleteFile(self, remote_file):
          """Delete the 'remote_file'.
  
          'remote_file' -- A relative path to the file to be deleted."""
  
--- 152,170 ----
  
          The program is uploaded to the default directory on the remote
          host, run, and then deleted."""
          
          self.UploadFile(path)
!         result = self.Run(os.path.basename(path),
                            arguments,
                            environment,
!                           timeout,
!                           relative = True)
          self.DeleteFile(path)
          return result
          
          
      def DeleteFile(self, remote_file):
          """Delete the 'remote_file'.
  
          'remote_file' -- A relative path to the file to be deleted."""
  
Index: qm/test/classes/ssh_host.py
===================================================================
RCS file: /home/qm/Repository/qm/qm/test/classes/ssh_host.py,v
retrieving revision 1.2
diff -c -5 -p -r1.2 ssh_host.py
*** qm/test/classes/ssh_host.py	15 Jun 2006 13:40:14 -0000	1.2
--- qm/test/classes/ssh_host.py	18 Aug 2006 00:35:18 -0000
*************** class SSHHost(Host):
*** 69,85 ****
  
          If not empty, the user name that should be used when
          connecting to the remote host."""
          )
      
!     def Run(self, path, arguments, environment = None, timeout = -1):
  
!         if self.default_dir and not os.path.isabs(path):
!             if (path.find(os.path.sep) != -1
!                 or (os.path.altsep
!                     and path.find(os.path.altsep) != -1)):
!                 path = os.path.join(self.default_dir, path)
          path, arguments = self._FormSSHCommandLine(path, arguments,
                                                     environment)
          return super(SSHHost, self).Run(path, arguments, None, timeout)
  
  
--- 69,90 ----
  
          If not empty, the user name that should be used when
          connecting to the remote host."""
          )
      
!     def Run(self, path, arguments, environment = None, timeout = -1,
!             relative = False):
  
!         default_dir = self.default_dir
!         if not default_dir:
!             default_dir = os.curdir
!         if (relative
!             or (not os.path.isabs(path)
!                 and (path.find(os.path.sep) != -1
!                      or (os.path.altsep
!                          and path.find(os.path.altsep) != -1)))):
!             path = os.path.join(default_dir, path)
          path, arguments = self._FormSSHCommandLine(path, arguments,
                                                     environment)
          return super(SSHHost, self).Run(path, arguments, None, timeout)
  
  


From njs at pobox.com  Fri Aug 18 00:21:50 2006
From: njs at pobox.com (Nathaniel Smith)
Date: Thu, 17 Aug 2006 17:21:50 -0700
Subject: [qmtest] algorithms with less storage for producing results.xml?
In-Reply-To: <Pine.LNX.4.61.0608171101180.7802@cag.csail.mit.edu>
References: <Pine.LNX.4.61.0608171101180.7802@cag.csail.mit.edu>
Message-ID: <20060818002150.GB9483@frances.vorpus.org>

On Thu, Aug 17, 2006 at 11:45:37AM -0400, Allyn Dimock wrote:
> [ This had not been an issue for us when using qmtest 2.0: the xml report
> not being availble at the time, we reverse engineered the results.qmt
> format to generate the reports that we wanted in one pass per report (one 
> summary report that was e-mailed to developers and detais were in a 
> collection of html files referencable from the rt ticket tracker system).
>   In 2.3 we started relying on results.xml since the results.qmt format 
> had changed from 2.0 and we did not want to reverse engineer multiple 
> times when a non-proprietary format was available. ]

Note also that no reverse-engineering is required -- you can write an
implementation of qm.test.result_stream.ResultStream that does
whatever reporting you like.  This can then be plugged into qmtest
(using the standard qmtest plugin machinery, whose details I no
longer remember) to process results directly while 'qmtest run' is
running. or after-the-fact -- 'qmtest summarize' can read results out
of a .qmt file and feed the results into your reporting class.

-- Nathaniel

-- 
So let us espouse a less contested notion of truth and falsehood, even
if it is philosophically debatable (if we listen to philosophers, we
must debate everything, and there would be no end to the discussion).
  -- Serendipities, Umberto Eco


From nealem at vastsystems.com.au  Thu Aug 31 04:48:05 2006
From: nealem at vastsystems.com.au (Neale Morison)
Date: Thu, 31 Aug 2006 14:48:05 +1000
Subject: Handling large numbers of very similar tests
Message-ID: <526D9C4F57617D4EA35E1D76D3825CD702E1AE@exchange.vast.local>

Hi all.
We are using QMTest to run a large number (120K) of very similar tests.
We are trying to find a way to generate the specification for these
tests by some sort of batch or scripting, rather than creating 120K
individual specifications. We're having trouble interpreting the manual
and finding out whether this is possible.

Can anyone point us in the right direction, or confirm that it is not
possible?
Thanks a lot,
Neale
 
Neale Morison
Manager, System Integration, Testing and Release Group
n.morison at vastsystems.com.au
VaST Systems Technology Corporation
29 Christie St St Leonards, NSW 2065
Direct: +61 2 8198 8627  Main: +61 2 8198 8600   www.vastsystems.com
<http://www.vastsystems.com/> 


From stefan at codesourcery.com  Thu Aug 31 13:23:30 2006
From: stefan at codesourcery.com (Stefan Seefeld)
Date: Thu, 31 Aug 2006 09:23:30 -0400
Subject: [qmtest] Handling large numbers of very similar tests
In-Reply-To: <526D9C4F57617D4EA35E1D76D3825CD702E1AE@exchange.vast.local>
References: <526D9C4F57617D4EA35E1D76D3825CD702E1AE@exchange.vast.local>
Message-ID: <44F6E2D2.6030007@codesourcery.com>

Neale Morison wrote:
> Hi all.
> We are using QMTest to run a large number (120K) of very similar tests.
> We are trying to find a way to generate the specification for these
> tests by some sort of batch or scripting, rather than creating 120K
> individual specifications. We're having trouble interpreting the manual
> and finding out whether this is possible.
> 
> Can anyone point us in the right direction, or confirm that it is not
> possible?

Handling very large numbers of tests is definitely possible, though, as you
point out, using the default test database doesn't scale well up to such
numbers.
Instead, you may consider extending QMTest by providing your own test
database implementation (see
http://www.codesourcery.com/public/qmtest/qm-snapshot/qm/test/doc/html/sec-ref-writing-database-classes.html)

I'm presently in the process of enhancing the QMTest Tutorial to better
document how to do this. One new database type I just added, and which
I will use to illustrate the process of customization and extension,
simply scans a directory for files with particular extensions (such as '.c')
and associates particular test types with them ('CompilationTest', say).

Your database implementation needs to be hooked up to whatever representation
you currently have for your tests, so you don't need one '.qmt' file per test
instance as the default database requires.

Don't hesitate to ask if you need further assistance !

Regards,
		Stefan

-- 
Stefan Seefeld
CodeSourcery
stefan at codesourcery.com
(650) 331-3385 x718



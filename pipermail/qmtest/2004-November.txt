From ssinger at navtechinc.com  Wed Nov  3 20:34:52 2004
From: ssinger at navtechinc.com (ssinger at navtechinc.com)
Date: Wed, 3 Nov 2004 20:34:52 +0000 (GMT)
Subject: Projects using QMTest?
Message-ID: <Pine.LNX.4.44.0411032024330.28712-100000@pcnavykfsjs.ykf.navtechinc.com>


I'm wondering what open-source projects are currently using QMTest?

I've seen G++ link on the 
website (http://www.codesourcery.com/qmtest/v3_abi_testsuite.html) 
that doesn't seem to work.  

I did notice that the FireBird database is using QMTest.  Anything else?

I'd like to see some examples of it in action on projects of moderate 
complexity.




-- 
Steven Singer                                       ssinger at navtechinc.com
Dispatch Systems                            Phone:  519-747-1170 ext 282
Navtech Systems Support Inc.                AFTN:   CYYZXNSX SITA: YYZNSCR
Waterloo, Ontario                           ARINC:  YKFNSCR



From seefeld at sympatico.ca  Thu Nov  4 00:56:21 2004
From: seefeld at sympatico.ca (Stefan Seefeld)
Date: Wed, 03 Nov 2004 19:56:21 -0500
Subject: [qmtest] Projects using QMTest?
In-Reply-To: <Pine.LNX.4.44.0411032024330.28712-100000@pcnavykfsjs.ykf.navtechinc.com>
References: <Pine.LNX.4.44.0411032024330.28712-100000@pcnavykfsjs.ykf.navtechinc.com>
Message-ID: <41897E35.9030308@sympatico.ca>

ssinger at navtechinc.com wrote:
> I'm wondering what open-source projects are currently using QMTest?
> 
> I've seen G++ link on the 
> website (http://www.codesourcery.com/qmtest/v3_abi_testsuite.html) 
> that doesn't seem to work.  
> 
> I did notice that the FireBird database is using QMTest.  Anything else?
> 
> I'd like to see some examples of it in action on projects of moderate 
> complexity.

synopsis (http://synopsis.fresco.org) is using qmtest. It's a work in
progress, and there's not much to 'see'. The test database is tailored
at synopsis' specific needs:
http://synopsis.fresco.org/viewsvn/synopsis-Synopsis/trunk/tests/classes/

Regards,
		Stefan


From mark at codesourcery.com  Thu Nov  4 04:29:49 2004
From: mark at codesourcery.com (Mark Mitchell)
Date: Wed, 03 Nov 2004 20:29:49 -0800
Subject: [qmtest] Projects using QMTest?
In-Reply-To: <Pine.LNX.4.44.0411032024330.28712-100000@pcnavykfsjs.ykf.navtechinc.com>
References: <Pine.LNX.4.44.0411032024330.28712-100000@pcnavykfsjs.ykf.navtechinc.com>
Message-ID: <4189B03D.1050107@codesourcery.com>

ssinger at navtechinc.com wrote:
> I'm wondering what open-source projects are currently using QMTest?
> 
> I've seen G++ link on the 
> website (http://www.codesourcery.com/qmtest/v3_abi_testsuite.html) 
> that doesn't seem to work.  

Thanks for pointing that out!  It has now been fixed.

-- 
Mark Mitchell
CodeSourcery, LLC
mark at codesourcery.com


From mats.d.wichmann at intel.com  Thu Nov  4 14:29:17 2004
From: mats.d.wichmann at intel.com (Wichmann, Mats D)
Date: Thu, 4 Nov 2004 06:29:17 -0800
Subject: [qmtest] Projects using QMTest?
Message-ID: <A06801158AE07847B27A52C1A074BC1D06878FA0@fmsmsx404.amr.corp.intel.com>


>ssinger at navtechinc.com wrote:
>> I'm wondering what open-source projects are currently using QMTest?
>> 
>> I've seen G++ link on the 
>> website (http://www.codesourcery.com/qmtest/v3_abi_testsuite.html) 
>> that doesn't seem to work.  
>
>Thanks for pointing that out!  It has now been fixed.


The LSB project is using that testsuite as part of our
conformace validation program, FWIW, and it's quite
possible that we'll expand our use of qmtest in the future.



From lavanyag at virtusa.com  Mon Nov 22 12:00:31 2004
From: lavanyag at virtusa.com (Lavanya Arikala Gunalan)
Date: Mon, 22 Nov 2004 17:30:31 +0530
Subject: Regarding installation
Message-ID: <55D5E3424D32B946A5DADB1FBFB9295FA81C36@ms-mailsvr.Virtusa.com>


hi,
I am  unable to install the tool, please give me suggestion to install
the tool both in Windows and linux


Thanks & Regards
Lavanya A.G.
Team Virtusa
Ph: 52002700   Extn 3502
Mobile : 9840856456
Email: Lavanyag at virtusa.com <mailto:Lavanyag at virtusa.com> 
         www.virtusa.com <http://www.virtusa.com/> 
 
 



  <http://www.incredimail.com/index.asp?id=54475>


---------------------------------------------------------------------------------------------
This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://sourcerytools.com/pipermail/qmtest/attachments/20041122/5db89c9c/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pie Charts Bkgrd.JPG
Type: image/jpeg
Size: 2371 bytes
Desc: Pie Charts Bkgrd.JPG
URL: <http://sourcerytools.com/pipermail/qmtest/attachments/20041122/5db89c9c/attachment.jpe>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: imstp_emo_en.gif
Type: image/gif
Size: 8816 bytes
Desc: imstp_emo_en.gif
URL: <http://sourcerytools.com/pipermail/qmtest/attachments/20041122/5db89c9c/attachment.gif>

From afunk at ll.mit.edu  Tue Nov 30 19:30:38 2004
From: afunk at ll.mit.edu (Andrew Funk)
Date: Tue, 30 Nov 2004 14:30:38 -0500
Subject: QMTest HPCS extensions
In-Reply-To: <41AC0FB9.2060509@codesourcery.com>
Message-ID: <002001c4d713$128ac010$7588229b@meriadoc>

Hi Mark,

See responses below:

> -----Original Message-----
> From: Mark Mitchell [mailto:mark at codesourcery.com] 
> Sent: Tuesday, November 30, 2004 1:14 AM
> To: Andrew Funk
> Subject: Re: QMTest HPCS extensions
> 
> 
> Andrew Funk wrote:
> > Hi Mark,
> > 
> > I would like to begin a discussion to determine the best way to
> > transition over to CodeSourcey the development of QMTest features in
> > support of HPCS.  Here are the latest versions of the 
> extension classes
> > and documentation.
> 
> Andy --
> 
> First, I apologize for taking so long to make progress here.
> 
> Second, do you have any objection to moving this discussion to the 
> QMTest mailing list?  I'd like to do that so that our discussions are 
> recorded for posterity, and for Stefan Seefeld, who will be starting 
> with us January 1st.  Stefan will be working on the HPCS 
> QMTest stuff, 
> so it would help to have the discussion on the lists where he can see 
> it, even before he starts.  I'm very excited about Stefan joining us 
> because I think it will give us a chance to make progress a lot more 
> quickly; I'm a bottleneck.  If you give me your permission, 
> I'll resend 
> your message and mine to the mailing lists.
> 
> Third, I've reviewed your work.  I think you've done a great job 
> understanding QMTest.  I'd like to start by figuring out how 
> to clean up 
> ParameterDatabase and make it a part of the standard QMTest 
> distribution.  Does that sound like a good plan to you?
> 

Agreed.  I am looking at the extensions I have written as a functional
prototype that will help us (development team) to understand the nature
of the functionality we (HPCS) want to get out of QMTest.  I would like
to leave it up to you and Stefan to decide how best to implement that
functionality and incorporate it into QMTest.  Of course I will be glad
to help out and especially to explain what I was trying to do with my
code if necessary.

> I'd like to make a few changes.  First, I think there's a conceptual 
> issue.  In particular, there are two kinds of replication in play. 
> There is replication on the part of the testsuite designer and on the 
> part of the testsuite executor.  For example, the former 
> might say "this 
> same code should be run through Sloccount and through a Cyclomatic 
> complexity tool".  The latter might say "all tests should be run with 
> one, two, and four processors".  Conceptually, the first kind of 
> replication should be part of the testsuite; the latter 
> should be part 
> of the context.  I say that because the testsuite designer 
> cannot know 
> how many processors are available.  Do you agree?  I think we could 
> handle the test-executor replication by using a variant of 
> MountDatabase; we would replicate the ParameterDatabase N times as 
> required to deal with the replication requested by the test-executor.
> 

That's a good point.  Perhaps it would be a good idea to separate out
the numbers of processors, and maybe some other platform-dependent
settings like compiler name and options.  For the NAS, there is actually
a lot of compiler settings in the make files that have to be edited
separately for each platform.  I thought about trying to pull this
information into a context, but I hadn't gotten around to it yet.

The only downside I can see of separating the concerns is that it might
make test specification more difficult (having to specify parameters in
two places).  Another one of my desired features was to explore more
user-friendly alternatives to editing the configuration file (e.g. make
it part of the GUI interface).  Improving the method of input might
eliminate any downside of separate concerns.  So I would be interested
to hear your thoughts on that as well.

> I'm a little confused about exactly how much parameterization 
> we need. 
> For example, is the first kind of parameterization (the part 
> done by the 
> testsuite designer) the same across all tests in the database?  For 
> example, do we want to run *all* tests through Sloccount and a 
> cyclomatic complexity tool?  Or is that kind of parameterization 
> different for different tests?
> 

I find it helpful to think about how the NAS is configured when thinking
about specific test cases, but I also want to be careful not to tailor
this solution just to the NAS.  With any luck this framework will be
capable of testing new benchmarks without changes or customization.  

Having said that, let me answer this question using NAS as an example.
Conceptually, we want to run the same suite of tests (e.g. sloccount,
complexity, compile and execute) on all available implementations of the
NAS.  In practice, we need to use different tools and settings to get
this data for the different implementations.  So with my current method
of input, this requires several independent sets of parameters.  If we
can separate out the platform and implementation-specific parameters
into contexts, this may make the test specification cleaner and more
intuitive.

These are my high-level thoughts.  I think there are a lot of specific
issues that we may want to focus on one at at time.  So let me know
where you think we might want to start and I can try to give more
specific information about exactly what we want.

Thanks,
Andy 




From Diana.Bosio at cern.ch  Wed Jul  7 08:35:02 2004
From: Diana.Bosio at cern.ch (Diana Bosio)
Date: Wed, 07 Jul 2004 10:35:02 +0200
Subject: qmtest and XML
Message-ID: <40EBB5B6.5070307@cern.ch>

Hi,
from the white paper I gathered that there is a way to tell qmtest to 
produce output in XML, but I couldn't find any reference on how to do it 
in the manual. Is there a way to have the results in standard XML from 
the qmtest command line?

Thanks,
Diana
-- 
CERN, European Organization for Nuclear Research
IT Department, Grid Middleware
Geneva 23, CH-1211, Switzerland
Tel: ++ 41 22 767 0638	Fax: ++ 41 22 767 7155




From mark at codesourcery.com  Thu Jul  8 07:32:19 2004
From: mark at codesourcery.com (Mark Mitchell)
Date: Thu, 08 Jul 2004 00:32:19 -0700
Subject: [qmtest] qmtest and XML
In-Reply-To: <40EBB5B6.5070307@cern.ch>
References: <40EBB5B6.5070307@cern.ch>
Message-ID: <40ECF883.1040109@codesourcery.com>

Diana Bosio wrote:

> Hi,
> from the white paper I gathered that there is a way to tell qmtest to 
> produce output in XML, but I couldn't find any reference on how to do 
> it in the manual. Is there a way to have the results in standard XML 
> from the qmtest command line?

Use the "--result-stream xml_result_stream.XMLResultStream" option to 
"qmtest run".

-- 
Mark Mitchell
CodeSourcery, LLC
(916) 791-8304
mark at codesourcery.com



From tellic3kc at yahoo.com  Tue Jul 13 20:07:20 2004
From: tellic3kc at yahoo.com (J C)
Date: Tue, 13 Jul 2004 13:07:20 -0700 (PDT)
Subject: passing data from one test to another
Message-ID: <20040713200720.2241.qmail@web52806.mail.yahoo.com>

Are there any mechanisms in QMTest to pass data
between 2 different tests during run-time?

For example I have a test suite with 2 tests ordered:
test1, test2(with prerequisite test1). When test1 is
done executing I want to pass some data test1 obtained
to test2 (which test2 will use during its execution).

>From what I understand of the context object: only
resources can pass data to tests through the context
during run-time. Also the result objects of previously
run tests don't appear to be accessible in the current
test.

If there isn't a builtin QMTest mechanism for this,
the temporary.TempDirectoryResource seems to be what
I'll use to communicate between tests.

Nick


		
__________________________________
Do you Yahoo!?
New and Improved Yahoo! Mail - Send 10MB messages!
http://promotions.yahoo.com/new_mail 


From slowrey at nextone.com  Tue Jul 13 20:40:35 2004
From: slowrey at nextone.com (Scott Lowrey)
Date: Tue, 13 Jul 2004 16:40:35 -0400
Subject: [qmtest] passing data from one test to another
In-Reply-To: <20040713200720.2241.qmail@web52806.mail.yahoo.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com>
Message-ID: <40F448C3.8020705@nextone.com>

J C wrote:

>Are there any mechanisms in QMTest to pass data
>between 2 different tests during run-time?
>
>  
>
If you are developing custom test classes (or hacking the provided 
classes :), you can use a global namespace to store persistent data. 
 Let me know if you want further info.

Otherwise, and unless the QMTest developers have other ideas, I think 
you're stuck with using temp files.  Crude but effective.

-- 
*Scott Lowrey*
NexTone Communications
Germantown, Maryland

/(240)912-1369/
NexTone.com <http://nextone.com>



From mark at codesourcery.com  Tue Jul 13 22:51:49 2004
From: mark at codesourcery.com (Mark Mitchell)
Date: Tue, 13 Jul 2004 15:51:49 -0700
Subject: [qmtest] passing data from one test to another
In-Reply-To: <20040713200720.2241.qmail@web52806.mail.yahoo.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com>
Message-ID: <40F46785.4020901@codesourcery.com>

J C wrote:

>Are there any mechanisms in QMTest to pass data
>between 2 different tests during run-time?
>
>For example I have a test suite with 2 tests ordered:
>test1, test2(with prerequisite test1). When test1 is
>done executing I want to pass some data test1 obtained
>to test2 (which test2 will use during its execution).
>
>  
>
We don't make that easy because we don't think it is good test design.

QMTest is designed so that each test is independent.  Prerequisites are 
optimization hints, like "if this test fails, there is no point in 
running these other tests" -- they are not ways of passing data between 
tests. 

We do, however, provides "resources" which can construct data that is 
shared across tests -- and data from resources appears in the context of 
tests that depend on those resources.

-- 
Mark Mitchell
CodeSourcery, LLC
(916) 791-8304
mark at codesourcery.com



From Scott.Lowrey at comcast.net  Wed Jul 14 02:33:42 2004
From: Scott.Lowrey at comcast.net (Scott Lowrey)
Date: Tue, 13 Jul 2004 22:33:42 -0400
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40F46785.4020901@codesourcery.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com> <40F46785.4020901@codesourcery.com>
Message-ID: <40F49B86.9010109@comcast.net>

Mark Mitchell wrote:

> J C wrote:
>
>> Are there any mechanisms in QMTest to pass data
>> between 2 different tests during run-time?
>>
> We don't make that easy because we don't think it is good test design.
>

Have to disagree somewhat.  After considerable experience with QMTest, 
we've run into some brain twisters that don't seem to lend themselves to 
tidy, compartmentalized design.   Although I tell my team that data 
independence is important and that they should look at the problem from 
several angles to find the best way to structure a suite, it ain't 
always easy.

An alternative is to pack several tests into one with multiple 
opportunities to annotate and fail along the way, but that sort of 
defeats the whole purpose of using QMTest, right?

Maybe it's just me.  :)



From seefeld at sympatico.ca  Tue Jul 13 23:29:34 2004
From: seefeld at sympatico.ca (Stefan Seefeld)
Date: Tue, 13 Jul 2004 19:29:34 -0400
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40F49B86.9010109@comcast.net>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com> <40F46785.4020901@codesourcery.com> <40F49B86.9010109@comcast.net>
Message-ID: <40F4705E.2090107@sympatico.ca>

Scott Lowrey wrote:

> An alternative is to pack several tests into one with multiple 
> opportunities to annotate and fail along the way, but that sort of 
> defeats the whole purpose of using QMTest, right?

Exactly. While I agree with you about the occasional difficulty to
separate test scenarios, I think that qmtest does a good job at
reminding you what unit testing is all about ;-)
If you can't split a test into (independent) sub-units, keep them together !
Pushing different annotations into the result object to distinguish test
failures is what qmtest offers you to recover the information later.

Regards,
		Stefan



From mark at codesourcery.com  Sat Jul 17 18:14:37 2004
From: mark at codesourcery.com (Mark Mitchell)
Date: Sat, 17 Jul 2004 11:14:37 -0700
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40F49B86.9010109@comcast.net>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com> <40F46785.4020901@codesourcery.com> <40F49B86.9010109@comcast.net>
Message-ID: <40F96C8D.2020102@codesourcery.com>

Scott Lowrey wrote:

> Mark Mitchell wrote:
>
>> J C wrote:
>>
>>> Are there any mechanisms in QMTest to pass data
>>> between 2 different tests during run-time?
>>>
>> We don't make that easy because we don't think it is good test design.
>>
>
> Have to disagree somewhat.  After considerable experience with QMTest, 
> we've run into some brain twisters that don't seem to lend themselves 
> to tidy, compartmentalized design.   Although I tell my team that data 
> independence is important and that they should look at the problem 
> from several angles to find the best way to structure a suite, it 
> ain't always easy.
>
> An alternative is to pack several tests into one with multiple 
> opportunities to annotate and fail along the way, but that sort of 
> defeats the whole purpose of using QMTest, right?

I think the issue here is more conceptual than technical.

For us, a canonical example comes from testing a compiler.  Our 
canonical test is a single file which must be compiled, linked, and 
run.   Success means doing all of that and exiting with exit code zero.  
We could look at that as three separate tests (a compile test, a link 
test, and a run test) with a data dependency -- but we don't because 
users of compilers don't think of it that way.  Either the compiler 
works for that program or it doesn't.  So, we have just one test, but 
the annotations indicate what kind of failure occurred.

Perhaps you could explain your use case and we could see if there's a 
way to do it in QMTest that makes sense?  If not, then we can think 
about what we could do to QMTest to improve it.

Thanks,

-- 
Mark Mitchell
CodeSourcery, LLC
(916) 791-8304
mark at codesourcery.com



From slowrey at nextone.com  Mon Jul 19 19:41:09 2004
From: slowrey at nextone.com (Scott Lowrey)
Date: Mon, 19 Jul 2004 15:41:09 -0400
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40F96C8D.2020102@codesourcery.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com> <40F46785.4020901@codesourcery.com> <40F49B86.9010109@comcast.net> <40F96C8D.2020102@codesourcery.com>
Message-ID: <40FC23D5.2070206@nextone.com>

Mark Mitchell wrote:

> For us, a canonical example comes from testing a compiler.  Our 
> canonical test is a single file which must be compiled, linked, and 
> run.   Success means doing all of that and exiting with exit code 
> zero.  We could look at that as three separate tests (a compile test, 
> a link test, and a run test) with a data dependency -- but we don't 
> because users of compilers don't think of it that way.  Either the 
> compiler works for that program or it doesn't.  So, we have just one 
> test, but the annotations indicate what kind of failure occurred.
>
> Perhaps you could explain your use case and we could see if there's a 
> way to do it in QMTest that makes sense?  If not, then we can think 
> about what we could do to QMTest to improve it.
>
OK, here's a case that I'm dealing with today.

Our tests exercise a remote device that handles telecom traffic.  There 
are several processes running on it - it's a Unix box - and we hit those 
processes with network traffic generated on the local host.  One of 
those processes is highly-concurrent and real time; it is crucial to the 
operation of the system-under-test.  Although it should never crash or 
hang, it's written in C, so it might.  This process runs throughout the 
duration of a test session.

If a test results in a crash/lockup, we need to know immediately and 
stop testing.  The test classes themselves could do the "health check" 
but, even if they did, they could not affect the onward movement of the 
QMTest execution engine; not without making every single test dependent 
on the one before it, which is not an option for us because the tests 
are not sequential in nature and may even be randomly shuffled.

I'm toying with the idea of writing a custom execution engine that 
watches the SUT and does all the necessary monitoring and data gathering 
in the event of a catastrophic failure.   This engine could also 
terminate the test loop in the event of said failure.  We've already 
tweaked cmdline.py a tiny bit to get some SUT information prior to 
testing so it looks like we're headed down that path...

Here's another one, and probably more relevant:

We have hundreds of tests that simulate telephone calls.  They are quite 
self-contained except for a piece of underlying software that requires 
us to increment a UDP port number for each test.   The new port number 
must be the number used in the preceding test plus two.

Because our custom test class uses the same model as python.ExecTest, 
each test is exec'd.   Say we kept the port number in the context.  We 
can pass the port number *to* the test but the test can't increment the 
number and pass it *back* for the next test because of the exec.  So, we 
cheated by defining a global variable in our custom test class and then 
adding that variable reference to the global namespace that is passed to 
the test.

Are these approaches flawed?  

-- 
*Scott Lowrey*
NexTone Communications
Germantown, Maryland

/(240)912-1369/
NexTone.com <http://nextone.com>



From eichin at metacarta.com  Mon Jul 19 19:54:08 2004
From: eichin at metacarta.com (eichin at metacarta.com)
Date: 19 Jul 2004 15:54:08 -0400
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40FC23D5.2070206@nextone.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com>
	<40F46785.4020901@codesourcery.com> <40F49B86.9010109@comcast.net>
	<40F96C8D.2020102@codesourcery.com> <40FC23D5.2070206@nextone.com>
Message-ID: <7gwu0z7oyn.fsf@pikespeak.metacarta.com>


> We have hundreds of tests that simulate telephone calls.  They are
> quite self-contained except for a piece of underlying software that

In tests I have that are similar in concept to this, I've tried two
different approaches - the first is to have scripts that generate the
entire pile of individual tests (with the chosen port numbers) up
front, and then run qmtest on that.  The second is to treat the "set
of calls" as a single test, and just have qmtest run the whole thing
as one test - this scales a lot better, and when the system has passed
the primary smoke tests, these tests are mostly "is this data handled
properly" and so don't need as much detail up the chain.

Another thought is that if your udp port state is related to the SUT
but not to the tests per-se, abstracting it out into a test-runner
that keeps that state and makes the "real" connections, then each
qmtest-level test sends a message to the test-runner, instead of doing
it directly.  That also lets (though this is conflating your two cases
a bit) the "runner" notice the SUT failing and then it can cancel (or
rather, stop accepting requests) for the remainder of the run...


From mark at codesourcery.com  Tue Jul 20 06:50:03 2004
From: mark at codesourcery.com (Mark Mitchell)
Date: Mon, 19 Jul 2004 23:50:03 -0700
Subject: [qmtest] passing data from one test to another
In-Reply-To: <40FC23D5.2070206@nextone.com>
References: <20040713200720.2241.qmail@web52806.mail.yahoo.com> <40F46785.4020901@codesourcery.com> <40F49B86.9010109@comcast.net> <40F96C8D.2020102@codesourcery.com> <40FC23D5.2070206@nextone.com>
Message-ID: <40FCC09B.40609@codesourcery.com>

Scott Lowrey wrote:

> Mark Mitchell wrote:
>
>> For us, a canonical example comes from testing a compiler.  Our 
>> canonical test is a single file which must be compiled, linked, and 
>> run.   Success means doing all of that and exiting with exit code 
>> zero.  We could look at that as three separate tests (a compile test, 
>> a link test, and a run test) with a data dependency -- but we don't 
>> because users of compilers don't think of it that way.  Either the 
>> compiler works for that program or it doesn't.  So, we have just one 
>> test, but the annotations indicate what kind of failure occurred.
>>
>> Perhaps you could explain your use case and we could see if there's a 
>> way to do it in QMTest that makes sense?  If not, then we can think 
>> about what we could do to QMTest to improve it.
>>
> OK, here's a case that I'm dealing with today.
>
> Our tests exercise a remote device that handles telecom traffic.  
> There are several processes running on it - it's a Unix box - and we 
> hit those processes with network traffic generated on the local host.  
> One of those processes is highly-concurrent and real time; it is 
> crucial to the operation of the system-under-test.  Although it should 
> never crash or hang, it's written in C, so it might.  This process 
> runs throughout the duration of a test session.
>
> If a test results in a crash/lockup, we need to know immediately and 
> stop testing.  The test classes themselves could do the "health check" 
> but, even if they did, they could not affect the onward movement of 
> the QMTest execution engine; not without making every single test 
> dependent on the one before it, which is not an option for us because 
> the tests are not sequential in nature and may even be randomly shuffled.
>
> I'm toying with the idea of writing a custom execution engine that 
> watches the SUT and does all the necessary monitoring and data 
> gathering in the event of a catastrophic failure.   This engine could 
> also terminate the test loop in the event of said failure.  We've 
> already tweaked cmdline.py a tiny bit to get some SUT information 
> prior to testing so it looks like we're headed down that path...

That's interesting.

If it weren't for the dynamic nature, you'd use a resource -- it would 
set up the long-running process, and all your tests would depend upon 
that resource.

> We have hundreds of tests that simulate telephone calls.  They are 
> quite self-contained except for a piece of underlying software that 
> requires us to increment a UDP port number for each test.   The new 
> port number must be the number used in the preceding test plus two.

Also interesting.

I'm going to chew on those a bit, and see what we can come up with.

Thanks,

-- 
Mark Mitchell
CodeSourcery, LLC
(916) 791-8304
mark at codesourcery.com



From Matthew.E.Levine at disney.com  Wed Jul 21 18:42:28 2004
From: Matthew.E.Levine at disney.com (Levine, Matthew E.)
Date: Wed, 21 Jul 2004 11:42:28 -0700
Subject: Registering tests
Message-ID: <40FEB914.5020001@disney.com>

Is there any way to have a test class automatically registered when you 
start QMTest?  If not it would be a very useful feature to allow 
automatic registration of new test classes.

- Matt



From slowrey at nextone.com  Thu Jul 22 12:07:51 2004
From: slowrey at nextone.com (Scott Lowrey)
Date: Thu, 22 Jul 2004 08:07:51 -0400
Subject: [qmtest] Registering tests
In-Reply-To: <40FEB914.5020001@disney.com>
References: <40FEB914.5020001@disney.com>
Message-ID: <40FFAE17.6020801@nextone.com>

Levine, Matthew E. wrote:

> Is there any way to have a test class automatically registered when 
> you start QMTest?  If not it would be a very useful feature to allow 
> automatic registration of new test classes.


Why do you feel you need to register a test more than once?  After a 
test or resource class is registered the first time, it's good to go 
unless you overwrite the 'classes' table (classes.qmc) in the database.

-Scott



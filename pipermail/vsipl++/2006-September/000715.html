<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [vsipl++] [patch] Tutorial updates
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:vsipl%2B%2B%40codesourcery.com?Subject=Re%3A%20%5Bvsipl%2B%2B%5D%20%5Bpatch%5D%20Tutorial%20updates&In-Reply-To=%3C45080304.6010704%40codesourcery.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000710.html">
   <LINK REL="Next"  HREF="000719.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[vsipl++] [patch] Tutorial updates</H1>
    <B>Jules Bergmann</B> 
    <A HREF="mailto:vsipl%2B%2B%40codesourcery.com?Subject=Re%3A%20%5Bvsipl%2B%2B%5D%20%5Bpatch%5D%20Tutorial%20updates&In-Reply-To=%3C45080304.6010704%40codesourcery.com%3E"
       TITLE="[vsipl++] [patch] Tutorial updates">jules at codesourcery.com
       </A><BR>
    <I>Wed Sep 13 13:09:24 UTC 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="000710.html">[vsipl++] [patch] Tutorial updates
</A></li>
        <LI>Next message: <A HREF="000719.html">[vsipl++] [patch] Tutorial updates
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#715">[ date ]</a>
              <a href="thread.html#715">[ thread ]</a>
              <a href="subject.html#715">[ subject ]</a>
              <a href="author.html#715">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Don,

This looks good.  I have several suggestions below on the tutorial chapter.
Use them as you please :)  Once you're happy please check it in.  We can
continue to incorporate edits as we review at the whole document.

I haven't had a chance to read the reference chapter yet, I will send
comments on that later.

				thanks,
				-- Jules

 &gt; +    &lt;para&gt;
 &gt; +      In addition to the accumulate and trace modes, which have 
pre-defined
 &gt; +      output formats, Sourcery VSIPL++ exposes a profiling API that 
you can
                                                     ^^ Performance API
 &gt; +      use to gather data directly on individual objects, such as FFTs.
 &gt; +      If you need finer control of what operations are profiled, or 
if you
 &gt; +      want to record the profiling data in a custom format, you may 
wish to
 &gt; +      use this API directly.  See &lt;xref linkend=&quot;performance_api&quot;/&gt; for
 &gt; +      more details.
 &gt; +    &lt;/para&gt;
 &gt; +&lt;table xml:id=&quot;supported_ops&quot; frame=&quot;none&quot; rowsep=&quot;0&quot;&gt;
 &gt; +  &lt;title&gt;Operations Supporting Profiling&lt;/title&gt;


 &gt;      &lt;para&gt;
 &gt;        See the file &lt;filename&gt;profiling.txt&lt;/filename&gt; for a detailed
 &gt;        explanation of the profiler output for each of the functions 
above.
 &gt; +      See the file &lt;filename&gt;profiling.txt&lt;/filename&gt; for a detailed

Isn't profiling.txt now Chapter 5?

 &gt; +      explanation of the profiler output for each of the functions 
above.
 &gt; +      For information about how to configure the library for profiling,
 &gt; +      see the Quickstart also.
 &gt;      &lt;/para&gt;

 &gt; +    &lt;para&gt;
 &gt; +      This macro enables profiling operations in several different areas
 &gt; +      of the library, depending on the value of
 &gt; +      &lt;replaceable&gt;mask&lt;/replaceable&gt;.  To profile all operations, use
 &gt; +      the value &lt;literal&gt;15&lt;/literal&gt;.  See &lt;xref 
linkend=&quot;mask-values&quot;/&gt;
 &gt; +      for other possible values.

I would mention the motivation behind why we have a mask:

   &quot;Since profiling can introduce overhead, especially for element-wise
   expressions, this macro allows you to choose which operations in the
   library are profiled.  To profile all operations, use the value
   &lt;literal&gt;15&lt;/literal&gt;.  See ...&quot;
 &gt; +    &lt;/para&gt;

 &gt; +    &lt;note&gt;
 &gt; +      &lt;para&gt;
 &gt; +	Profiling support requires that you link with a version of Sourcery
 &gt; +	VSIPL++ that supports profiling.  If you have received a binary
 &gt; +	distribution of Sourcery VSIPL++ from CodeSourcery, you probably
 &gt; +	already have an appropriate version of the library.  If you are
 &gt; +	building Sourcery VSIPL++ yourself, see the Quickstart guide for
 &gt; +	more information about the requirements for building Sourcery
 &gt; +	VSIPL++ with profiling enabled.

We've changed things so that all libraries support profiling, if a timer
is provided:

   &quot;Profiling requires that the library be configured with a high-resolution
   timer.  Binary distributions of Sourcery VSIPL++ from CodeSourcery have
   this done.  If you are building Sourcery VSIPL++ from source, see the
   Quickstart guide for more information about configuring high-resolution
   timers.&quot;

 &gt; +      &lt;/para&gt;
 &gt; +    &lt;/note&gt;



 &gt; +    &lt;section&gt;&lt;title&gt;Setup&lt;/title&gt;
 &gt; +    &lt;para&gt;
 &gt; +      The only computation performed in the setup phase is a forward FFT
 &gt; +      that maps the pulse replica into the frequency domain.  This
 &gt; +      computation corresponds to the following line of the profiling
 &gt; +      data:
 &gt; +&lt;screen&gt;Fft Fwd C-C by_ref 256 : 142119 : 1 : 10240 : 258.767
 &gt; +&lt;/screen&gt;
 &gt; +      The &quot;Fft Fwd C-C by_ref 256&quot; tag indicates that this computation
 &gt; +      is a 256-element forward FFT with complex, single-precision 
inputs
 &gt; +      and outputs, returning its result by reference.  The notation 
used
 &gt; +      for data types (e.g., &quot;C-C&quot; in this example) is given in
                                                          ^^ described
 &gt; +      &lt;xref linkend=&quot;data-type-names&quot;/&gt;.
 &gt; +    &lt;/para&gt;
 &gt; +
 &gt;      &lt;/section&gt;
 &gt; -    &lt;section id=&quot;trace-profile-data&quot;&gt;&lt;title&gt;Trace Profile Data&lt;/title&gt;
 &gt; +    &lt;section&gt;&lt;title&gt;Convert to frequency domain&lt;/title&gt;
 &gt;      &lt;para&gt;
 &gt; -      This mode is used similarly to accumulate mode, except that an
 &gt; -      extra parameter is passed to the creation of the 
&lt;code&gt;Profile&lt;/code&gt;
 &gt; -      object.
 &gt; -      &lt;screen&gt;Profile profile(&quot;/dev/stdout&quot;, pm_trace);&lt;/screen&gt;
 &gt; +      The next step of the computation is to convert from the time 
domain
 &gt; +      to the frequency domain.  In particular, an FFT is applied to 
a data
 &gt; +      cube of 64 pulses, each containing 256 range cells:

   &quot;In particular, a FFT is applied to each pulse of a data cube, which 
consists
   of 64 pulses each containing 256 range cells:&quot;

 &gt; +&lt;screen&gt;Fftm Fwd row_type C-C by_ref 64x256 : 1188144 : 1 : 1146880 
:<i> 3466.65
</I> &gt; +&lt;/screen&gt;
 &gt; +      For this FFT, the size is reported differently (rows x columns)
 &gt; +      because this is a two-dimensional FFT.

It's not a 2-D FFT, its an &quot;Multiple 1D FFT&quot;:

   &quot;For this operation, a Fftm object was used to perform multiple FFTs 
on each
    row of the data cube.&quot;

 &gt; +      The operation count (1.1 million) far outweighs that of
 &gt; +      any other step, except the inverse FFT.
 &gt; +      The performance measured was 3.5 GFLOPS/s on a 3.6 GHz Xeon.
 &gt; +      Since the theoretical peak performance on such
 &gt; +      a machine is about 14.4 GFLOP/s, the program has achieved an
 &gt; +      a very good 24% of peak.
 &gt; +      Other example programs measure in-cache FFT perfomance on vectors
 &gt; +      of the same size at 4.9 GFLOP/s.  Therefore, considering that the
 &gt; +      3.5 GFLOP/s includes cache overheads, the result is still good.

I would move the first sentence to a new paragraph following, to give it
some more context:

   &quot;Since the operation count (1.1 million) of the FFT (and inverse
   FFT) outweigh the rest of the computation, the overall performance
   will be very close to the FFT performance.&quot;

 &gt; +    &lt;/para&gt;
 &gt; +    &lt;/section&gt;
 &gt; +    &lt;section&gt;&lt;title&gt;Convolution&lt;/title&gt;
 &gt; +    &lt;para&gt;
 &gt; +      The actual convolution consists of a vector-matrix 
multiplication.
 &gt; +      The corresponding profiling output is:
 &gt; +&lt;screen&gt;Expr_Loop_Vmmul 2D vmmul(C,C) 64x256 : 1539531 : 1 : 98304 : 
229.321
 &gt; +&lt;/screen&gt;
 &gt; +      Sourcery VSIPL++ chose to evaluate this expression by 
performing a
 &gt; +      row-wise vector-vector multiplication on each of the rows of the
 &gt; +      matrix.  Therefore, there is a second line:
 &gt; +&lt;screen&gt;Expr_SIMD_VV-simd::vmul 1D *(C,C) 256 : 316674 : 64 : 1536 : 
1114.86
 &gt; +&lt;/screen&gt;
 &gt; +      The tag used for this expression is &quot;*(C,C)&quot;.  The profiling 
tag for
 &gt; +      many operations is shown using a prefix notation; the operation
 &gt; +      performed is followed by the types of the arguments.  The 
&quot;simd&quot; tag
 &gt; +      indicates that VSIPL++ used the Single Instruction Multiple 
Data (SIMD)
 &gt; +      facilities on the Xeon architecture for maximum performance.
 &gt; +    &lt;/para&gt;
 &gt; +    &lt;para&gt;
 &gt; +      The tick count for the vector-matrix multiplication (vmmul) 
includes
 &gt; +      the time spent in the multiple row-wise scalar-vector 
multiplications.
 &gt; +      Therefore the total number of time used by the program is 
*not* the
 &gt; +      sum of the tick counts given for each line.

We should mention why vmmul performance is less than the constituent 
scalar-vector
multiplies:

   &quot;You should notice the performance difference between the vmmul event and
   the individual scalar-vector multiplications.  Some of this is due to the
   extra work vmmul does to setup each individual multiplication: loop 
overhead
   and subview creation.  However, most of this is due to the overhead 
of profiling:
   the cost of accessing timers and the cost of maintaining profile data 
structures.

   In general, profiling overhead only slows the program execution but
   does not affect the measurements taken.  However, when an operation
   being profiled (such as vmmul) consists of many invocations of other
   profile operations (such as scalar-vector multiplication), measurements
   may be affected.

   When profiling is disabled, the performance of vmmul will be very 
close to the
   performance measured for the individual scalar-vector multiplications.&quot;

 &gt; +    &lt;/para&gt;
 &gt; +    &lt;/section&gt;
 &gt; +    &lt;section&gt;&lt;title&gt;Convert back to time domain&lt;/title&gt;
 &gt; +    &lt;para&gt;
 &gt; +      The last step of the algorithm is to convert back to the time 
domain
 &gt; +      by using an inverse FFT.  An inverse FFT is computationally
 &gt; +      equivalent to a forward FFT, except that an additional 
multiplication
 &gt; +      is performed to handle scaling.  The lines corresponding to the
 &gt; +      inverse FFT are:

When scaling is done is a choice left up to the user, so instead of
saying &quot;An inverse FFT is computationally equiv to a forward FFT,
except ...&quot; which implies this is true of all FFTs, you might say &quot;The
&quot;The inverse FFT is computationally equiv to the forward FFT, except
...&quot;, which implies this is true for the FFTs in the example.

 &gt; +&lt;screen&gt;Expr_Dense 2D *(C,s) 64x256 : 687285 : 1 : 32768 : 171.228
 &gt; +Expr_Loop 1D *(C,s) 16384 : 653265 : 1 : 32768 : 180.145
 &gt; +Fftm Inv row_type C-C by_ref 64x256 : 1559304 : 1 : 1146880 : 2641.48
 &gt; +&lt;/screen&gt;
 &gt; +      The first line describes a evaluation of a &quot;dense&quot; two-
 &gt; +      dimensional multiplication between a single-precision complex
 &gt; +      view (a matrix) and a single-precision scalar.  Note that
 &gt; +      scalars are represented using lower-case equivalents for
 &gt; +      the data types in the table above.
 &gt; +    &lt;/para&gt;
 &gt; +    &lt;para&gt;
 &gt; +      A &quot;dense&quot; matrix is one in which the values are packed
 &gt; +      tightly in memory with no intervening space between the rows
 &gt; +      or columns.  Therefore, the two-dimensional multiplication can
 &gt; +      be thought of as a 1-dimensional multiplication of a long vector.
 &gt; +      The evaluation of the 2-D operation includes the time required 
for
 &gt; +      the 1-D operation, together with a small amount of overhead.
 &gt; +      You can tell that this is the case as the time shown on the
 &gt; +      first line is slightly greater than the time shown on the second.
 &gt; +      Both show the same number of operations because they are
 &gt; +      referring to the same calculation.
 &gt; +    &lt;/para&gt;
 &gt; +    &lt;para&gt;
 &gt; +      Similarly, the time required for the inverse FFT includes both 
the
 &gt; +      time spent actually computing the FFT as well as the time 
required
 &gt; +      for the scaling multiplication.  Because the multiplication is 
not
 &gt; +      included in the theoretical operation count, the MOP/s count 
shown
 &gt; +      is somewhat smaller than than for the forward FFT.

I believe the theoretical operation count is intended to include this
scaling cost, but it requires extra effort on the part of the
implementation:

   &quot;For FFTs, Sourcery VSIPL++ uses the commonly accepted theoretical
    operation count of 5 N log2(N).  This includes the cost of scaling,
    which may be folded in with final twiddle factors.  However, as this
    example illustrates, not all FFT backends have this capability, as
    a result scaled FFTs often have a MOP/s rate lower than non-scaled
    FFTs.&quot;

 &gt; +    &lt;/para&gt;
 &gt; +    &lt;/section&gt;
 &gt; +  &lt;/section&gt;
 &gt; +  &lt;para&gt;
 &gt; +    The analysis presented in this section is only a portion of what
 &gt; +    one would do to verify an algorithm is performing as desired.
 &gt; +    Core routines utilizing techniques such as the fast convolution
 &gt; +    method comprise only a portion of larger programs whose
 &gt; +    performance is also of interest.
 &gt; +    The profiling capabilities utilized here can be extended to cover
 &gt; +    those areas of the application as well.
 &gt; +    See &lt;xref linkend=&quot;application_profiling&quot;/&gt; for more details.
 &gt; +  &lt;/para&gt;
 &gt; +  &lt;/section&gt;
 &gt; +    &lt;section&gt;&lt;title&gt;Trace Profile Data&lt;/title&gt;
 &gt; +    &lt;para&gt;

Flow suggestion: describe what trace mode is, then give details on how
to enable it:

   &quot;In trace mode, the profiler records each library call as a pair
   of events, allowing you to see where each call was made and when it
   returned. This provides two time stamps per call, showing not only
   which functions were executed, but how they were nested with respect
   to one another.  This mode is useful for investigating the execution
   sequence of your program.

   To enable trace mode, construct the 'Profile' object with a 'pm_trace'
   flag, as in this line:

     &lt;screen&gt;Profile profile(&quot;profile.txt&quot;, pm_trace);&lt;/screen&gt;

   Long traces can result when profiling in this mode, so be sure to
   avoid gathering more data than you have memory to store (and have
   time to process later).  The output is very similar to the output in
   accumulate mode.&quot;


 &gt; +      By passing an additional parameter to the 'Profile' constructor,
 &gt; +      you can switch from &quot;accumulate&quot; mode to &quot;trace&quot; mode.  This line:
 &gt; +&lt;screen&gt;Profile profile(&quot;profile.txt&quot;, pm_trace);&lt;/screen&gt;
 &gt; +      will cause Sourcery VSIPL++ to enter trace profiling mode.
 &gt; +      All computations performed by your program while
 &gt; +      &lt;code&gt;profile&lt;/code&gt; is in scope will be traced.
 &gt;        This mode is useful for investigating the execution sequence
 &gt;        of your program.
 &gt; -      The profiler simply records each library call as a pair of 
events,
 &gt; -      allowing you to see where it entered and exited scope in each 
case.
 &gt; +      The profiler records each library call as a pair of events,
 &gt; +      allowing you to see where each call was made and when it returned.
 &gt; +      This provides two time stamps per call, showing not only which
 &gt; +      functions were executed, but how they were nested with respect
 &gt; +      to one another.
 &gt; +      Long traces can result when profiling in this mode, so
 &gt; +      be sure to avoid gathering more data than you have memory to
 &gt; +      store (and have time to process later).  The output is very
 &gt; +      similar to the output in accumulate mode.
 &gt;      &lt;/para&gt;
 &gt;      &lt;para&gt;
 &gt; -      Long traces can result when profiling in this mode, so be sure to
 &gt; -      avoid taking more data than you have memory to store (and have 
time
 &gt; -      to process later).  The output is very similar to the output in
 &gt; -      accumulate mode.
 &gt; +      Here is a sample of the output obtained by running the fast
 &gt; +      convolution example in trace mode, which can also be run with
 &gt; +      the options
 &gt; +&lt;screen&gt;--vsipl++-profile-mode=trace 
--vsipl++-profile-output=profile.txt
 &gt; +&lt;/screen&gt;
 &gt;      &lt;/para&gt;
 &gt;      &lt;programlisting&gt;&lt;xi:include href=&quot;src/profile_trace.txt&quot; 
parse=&quot;text&quot;/&gt;
 &gt;      &lt;/programlisting&gt;
 &gt;      &lt;para&gt;
 &gt; -      For each event, the profiler outputs an event number, an 
indentifying
 &gt; -      tag, and the current timestamp (in &quot;ticks&quot;).  The next two fields
 &gt; -      differ depending on whether the event is coming into scope or 
out of
 &gt; -      scope.  When coming into scope, a zero is shown followed by the
 &gt; -      estimated count of floating point operations for that function.
 &gt; -      When exiting scope, the profiler displays the event number being
 &gt; -      closed followed by a zero.  In all cases, the timestamp (and
 &gt; -      intervals) may be converted to seconds by dividing by the
 &gt; -      'clocks_per_second' constant in the log file header.
 &gt; +      For each event, the Sourcery VSIPL++ outputs an event number,
 &gt; +      an indentifying tag, and the current timestamp (in &quot;ticks&quot;).
 &gt; +      The next two fields differ depending on whether the event
 &gt; +      marks the entry point of a library function or its return.
 &gt; +      At the start of a call, a zero is shown followed by the estimated
 &gt; +      count of floating point operations for that function.  When
 &gt; +      returning from a call, the profiler displays the event number
 &gt; +      created when the function was called, followed by a zero.
 &gt; +      In all cases, the timestamp (and intervals) may be converted to
 &gt; +      seconds by dividing by the 'clocks_per_second' constant in the
 &gt; +      log file header.
 &gt;      &lt;/para&gt;
 &gt; +    &lt;para&gt;
 &gt; +      In the break shown by the ellipses, the program is in the 
middle of
 &gt; +      performing the vector-matrix multiply, which has been broken down
 &gt; +      into 64 separate vector-multiplies.  The first two FFT's are
 &gt; +      completed, as shown by the fact that each have two entries,
 &gt; +      one for where the computation began and one for where it ended.
 &gt; +      The Vmmul function has started, but not yet finished, so it only
 &gt; +      has one entry as of yet.

The output includes the end event of the vmmul.  How about

   &quot;For brevity, events for some of the 64 scalar-vector mulitplies 
performed in
    the vmmul operation have been replaced with an ellipses.&quot;

 &gt; +    &lt;/para&gt;
 &gt;      &lt;/section&gt;
 &gt; -    &lt;section id=&quot;performance-api&quot;&gt;&lt;title&gt;Performance API&lt;/title&gt;
 &gt; +    &lt;section xml:id=&quot;performance_api&quot;&gt;&lt;title&gt;Performance API&lt;/title&gt;
 &gt;      &lt;para&gt;
 &gt;        An additional interface is provided for getting run-time 
profile data.
 &gt;        This allows you to selectively monitor the performance of a
 &gt; @@ -166,19 +331,19 @@
 &gt;      &lt;/para&gt;
 &gt;      &lt;para&gt;
 &gt;        Classes with the Performance API provide a function called
 &gt; -      &lt;code&gt;impl_performance&lt;/code&gt; that takes a string parameter 
and returns
 &gt; -      single-precision floating point number.
 &gt; +      &lt;code&gt;impl_performance&lt;/code&gt; that takes a std::string parameter
 &gt; +      and returns a single-precision floating point number.

Doesn't impl_performance take a 'char const*' parameter?

 &gt;      &lt;/para&gt;
 &gt;      &lt;para&gt;
 &gt;        The following call shows how to obtain an estimate of the 
performance
 &gt;        in number of operations per second:
 &gt; -
 &gt; -      &lt;screen&gt;float mops = fwd_fft.impl_performance(&quot;mops&quot;);&lt;/screen&gt;
 &gt; -
 &gt; -      An &quot;operation&quot; will vary depending on the object and type of data
 &gt; -      being processed.  For example, a single-precison Fft object will
 &gt; -      return the number of single-precison floating-point operations
 &gt; -      performed per second.
 &gt; +&lt;screen&gt;float mops = fwd_fft.impl_performance(&quot;mops&quot;);&lt;/screen&gt;
 &gt; +      The definition of &quot;operation&quot; varies depending on the object
 &gt; +      and type of data being processed.  For example, a single-precison
 &gt; +      Fft object will return the number of single-precison
 &gt; +      floating-point operations performed per second while a complex
 &gt; +      double-precision FFT object will return the number of double-
 &gt; +      precision floating-point operations performed per second.
 &gt;      &lt;/para&gt;
 &gt;      &lt;para&gt;
 &gt;        The table below lists the current types of information available.
 &gt; @@ -219,37 +384,59 @@
 &gt;  &lt;/table&gt;
 &gt;      &lt;/section&gt;
 &gt;    &lt;/section&gt;
 &gt; -  &lt;section id=&quot;application-profiling&quot;&gt;&lt;title&gt;Application 
Profiling&lt;/title&gt;
 &gt; +  &lt;section xml:id=&quot;application_profiling&quot;&gt;
 &gt; +    &lt;title&gt;Application Profiling&lt;/title&gt;
 &gt;      &lt;para&gt;
 &gt; -      The profiling mode provides an API that allows you to instrument
 &gt; -      your own code.  Here we introduce a new object, the
 &gt; -      &lt;code&gt;Scope_event&lt;/code&gt; class, and show you how to use it in 
your
 &gt; -      application.
 &gt; +      Sourcery VSIPL++ provides an interface that allows you to 
instrument
 &gt; +      your own code through the &lt;code&gt;Scope_event&lt;/code&gt; class.

For avoidance of doubt, you could mention that these events get included
in the profiling output:

   &quot;Sourcery VSIPL++ provides an interface that allows you to instrument
   your own code with profiling events that will be included in the
   accumulate mode and trace mode output.

   &quot;Profiling events are recorded by constructing a 'Scope_even' object.
   ... MERGE WITH NEXT PARAGRAPH&quot;

 &gt;      &lt;/para&gt;
 &gt;      &lt;para&gt;
 &gt; -      To create a &lt;code&gt;Scope_event&lt;/code&gt;, simply call the 
constructor, passing
 &gt; -      it the string that will become the event tag and, optionally, 
an integer
 &gt; -      value expressing the number of floating point operations that will
 &gt; -      be performed by the time the &lt;code&gt;Scope_event&lt;/code&gt; object 
is destroyed.
 &gt; -      For example, to  measure the time taken to compute a simple 
running sum
 &gt; -      of squares over a C array:
 &gt; +      To create a &lt;code&gt;Scope_event&lt;/code&gt;, call the constructor, 
passing
 &gt; +      it a std::string that will become the event tag and, 
optionally, an
 &gt; +      integer value expressing the number of floating point operations
 &gt; +      that will be performed by the time the &lt;code&gt;Scope_event&lt;/code&gt;
 &gt; +      object is destroyed.  For example, to measure the time taken to
 &gt; +      compute the main portion in the fast convolution example,
 &gt; +      modify the source as follows:
-- 
Jules Bergmann
CodeSourcery
<A HREF="http://sourcerytools.com/cgi-bin/mailman/listinfo/vsipl++">jules at codesourcery.com</A>
(650) 331-3385 x705

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000710.html">[vsipl++] [patch] Tutorial updates
</A></li>
	<LI>Next message: <A HREF="000719.html">[vsipl++] [patch] Tutorial updates
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#715">[ date ]</a>
              <a href="thread.html#715">[ thread ]</a>
              <a href="subject.html#715">[ subject ]</a>
              <a href="author.html#715">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://sourcerytools.com/cgi-bin/mailman/listinfo/vsipl++">More information about the vsipl++
mailing list</a><br>
</body></html>

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Example of parallel processing
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:vsipl%2B%2B%40codesourcery.com?Subject=Re%3A%20Example%20of%20parallel%20processing&In-Reply-To=%3C1D5F4E64B8C04F4C868B94AC9A532AF80DE5AA93%40ATLMAIL01.corp.weather.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   
   <LINK REL="Next"  HREF="001622.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Example of parallel processing</H1>
    <B>Cassanova, Bill</B> 
    <A HREF="mailto:vsipl%2B%2B%40codesourcery.com?Subject=Re%3A%20Example%20of%20parallel%20processing&In-Reply-To=%3C1D5F4E64B8C04F4C868B94AC9A532AF80DE5AA93%40ATLMAIL01.corp.weather.com%3E"
       TITLE="Example of parallel processing">BCassanova at weather.com
       </A><BR>
    <I>Tue Jul 13 20:24:31 UTC 2010</I>
    <P><UL>
        
        <LI>Next message: <A HREF="001622.html">[vsipl++] Example of parallel processing
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1621">[ date ]</a>
              <a href="thread.html#1621">[ thread ]</a>
              <a href="subject.html#1621">[ subject ]</a>
              <a href="author.html#1621">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi all,

 

I was just wondering if there is a good example available of the
foreach_vector method for parallel processing.

 

In particular I am thinking of a case with the following constraints:

 

(1)    A very large matrix.  Each row or block of rows should be
processed by a single processor.  The assumption is there will be
multiple processors and that using a parallel processing scheme makes
&quot;sense&quot;.

(2)    The primary thread, or using MPI terminology, the root process
will initialize or otherwise acquire the data.

(3)    The secondary thread or threads, assuming again MPI methodology,
mpirun was started with -np of greater than 1.

(4)    The secondary threads do the &quot;work&quot; on the matrix, a row or group
of rows at a time.

(5)    The main thread waits until all processing is complete.

 

I have searched the VSIPL++ distribution and have a working example of
more than one thread doing &quot;work&quot;.  I am having trouble understanding
how the main thread waits until all other processing is done.  Using MPI
terminology, how does one determine when the rank of the process is 0
and considered the root process and if so wait.

 

Example program:

 

template &lt;typename T&gt;

class matrix_walker

{

  Vector&lt;T&gt; my_replica;

  //Vector&lt;T&gt; my_tmp;

 

  public:

    template &lt; typename Block &gt;

    matrix_walker( Vector&lt;T,Block&gt; replica ):my_replica( replica )

    {

    }

 

    template&lt;typename Block1, typename Block2, dimension_type Dim&gt;

    void operator()

    (

      Vector&lt;T, Block1 &gt; in,

      Vector&lt;T,Block2&gt; out,

      Index&lt;Dim&gt;

    )

 

    {

      out = in * my_replica;

    }

 

int main(int argc, char** argv)

{

  // Initialize the library.

  vsipl init(argc, argv);

 

  unsigned int num_rows = 5;

  unsigned int num_columns = 10;

 

  vsip_csl::impl::Communicator comm =
vsip_csl::impl::default_communicator();

 

   typedef float value_type;

 

  typedef Map&lt;Block_dist, Whole_dist&gt; map_type;

 

  typedef Dense&lt;2, value_type, row2_type, map_type &gt; block_type;

 

  typedef Dense&lt;1, value_type, row1_type, Replicated_map&lt;1&gt; &gt;
replica_block_type;

 

  typedef Vector&lt;value_type, replica_block_type &gt; VEC;

 

  typedef Matrix&lt; value_type, block_type &gt; MATRIX;

 

  Replicated_map&lt;1&gt; replica_map;

 

  boost::shared_ptr&lt; VEC &gt; vec( new VEC( num_columns, replica_map ) );

 

  map_type map = map_type( num_processors(), 1);

 

  boost::shared_ptr&lt; MATRIX &gt; matrix( new MATRIX( num_rows, num_columns,
map ) );

  boost::shared_ptr&lt; MATRIX &gt; tmp_matrix( new MATRIX( num_rows,
num_columns, map ) );

 

  value_type idx = 0;

 

  for( index_type r = 0; r &lt; matrix-&gt;size(0); ++r )

  {

    for( index_type c = 0; c &lt; matrix-&gt;size(1); ++c )

    {

      matrix-&gt;put( r, c, idx+= 10 );

    }

  }

 

  (*vec) = 5;

 

(*tmp_matrix) = 0;

 

   matrix_walker&lt; value_type &gt; mw( vec-&gt;local() );

 

   foreach_vector&lt; tuple&lt;0,1&gt; &gt;( mw, (*matrix) );

 

// This prints out for as many threads as I started.  What I really want
is a way of determining when the worker threads are complete

//The process was started as mpirun -np 4

std::cout &lt;&lt; (*matrix) &lt;&lt; std::endl;  

 

// A second version of the program used:

// vsip_csl::impl::Communicator comm =
vsip_csl::impl::default_communicator();

// but the process only prints out the values that were assigned to that
processor

// If( comm..rank() == 0 )

// {

  // std::cout &lt;&lt; (*matrix) &lt;&lt; std::endl;

// }

 

Thanks,

Bill

-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://sourcerytools.com/pipermail/vsipl++/attachments/20100713/18456d8e/attachment.html">http://sourcerytools.com/pipermail/vsipl++/attachments/20100713/18456d8e/attachment.html</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	
	<LI>Next message: <A HREF="001622.html">[vsipl++] Example of parallel processing
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1621">[ date ]</a>
              <a href="thread.html#1621">[ thread ]</a>
              <a href="subject.html#1621">[ subject ]</a>
              <a href="author.html#1621">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://sourcerytools.com/cgi-bin/mailman/listinfo/vsipl++">More information about the vsipl++
mailing list</a><br>
</body></html>
